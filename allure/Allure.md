# [Allure一自动化测试报告](https://www.bilibili.com/video/BV1Hz4y1Q7Xu)

Allure 实现自动化测试用例与手工测试用例关联的作用

## allure介绍

* allure 是一个轻量级, 灵活的, 支持多语言的测试报告工具
* 多平台的, 奢华的report框架
* 可以为dev/qa 提供详尽的测试报告、测试步骤、log
* 也可以为管理层提供high level统计报告
* java语言开发的,支持pytest, javascript, PHP, ruby等
* 可以集成到Jenkins

## allure安装

## pytest-allure插件

## Allure 报告的生成

## allure 特性分析

### 场景:

​			希望在报告中看到测试功能, 子功能或场景, 测试步骤, 包括测试附加信息

### 解决:

​			`@feature`, `@story`, `@step,` `@attach`

### 步骤:

* import allure
* 功能加上`@allure.feature(“功能名称”)`
* 子功能上加`@allure.story(“子功能名称”)`
* 步骤上加`@allure.step(“步骤细节”)`
* `@allure.attach(“具体文本信息”)`, 需要附加的信息, 可以是数据, 文本, 图片, 视频, 网页
* 如果只测试登录功能运行的时候可以加限制过滤:
  * `pytest 文件名 --allure-features='购物车功能' --alure-stories='加入购物车'`

示例:

```python
def test_search(""):
    with allure.step("第一步: 打开搜索页面")
    
```

清理存在的目录使用 `--clean-alluredir`

## 按feature, story运行

注解`@allure.feature` 与 `@allure.story` 的关系

feature相当于一个功能, 一个大的模块, 将case分类到某个feature中, 报告中behavior中显示, 相当于testsuite

story相当于对应这个功能或者模块下的不同场景, 分支功能, 属于feature之下的结构, 报告在features中显示, 相当于testcase

feature与story类似于父子关系

```python
@allure.feature("登录类")
class TestLoginDemo:
    def test_login1(self):
        allure.attach('<img>...', attachment_type=allure.attachment_type.HTML)
        allure.attach.file('路径地址', attachment_type=allure.attachment_type.PNG)
        allure.attach.file()
    
```

Allure 生成包含日志, html代码片段, 图片, 视频

关联测试用例, 



## allure+pytest+selenium 实战演示







# [Junit结合下一代测试报告框架Allure2](https://www.bilibili.com/video/BV1jb41177zF)

### xUnit体系

Java: JUnit4, TestNG, JUnit5

python: Unittest, pytest

测试用例的管理概念

测试用例 testcase

测试用例核心元素

测试用例名字

测试用例标签

测试用例描述

测试过程

单元测试

Web自动化测试Selenium

App

定义测试套件

RunWith

SuiteClasses

测试套

用例分组标签

方法级别的标签

基于标签运行

include

## 数据驱动

### 参数化

JUnit

RunWith

Parameterized

### 数据驱动

数据来源: csv, yaml, xml, db, excel, json

读取数据源返回数组:

* 基于shcema: `List<Class>`
* 纯数据: `Array<Array<String, Object>>`

利用参数化进行数据与变量的对应

第一级能力: 参数化

第二级能力: 测试数据数据化

第三级能力: 业务逻辑数据化

第四级能力: 测试框架数据化

数据格式的选择

| 数据格式 | 优点            | 缺点                       |
| -------- | --------------- | -------------------------- |
| Excel    | 生成数据方便    | 二进制文件不利于版本管理   |
| CSV      | 可使用Excel编辑 | 文本格式方便版本管理       |
| YAML     | 格式完备        | 格式简单                   |
| XML      | 格式完备        | 冗长复杂                   |
| JSON     | 格式完备        | 不能编写注释, 格式相对复杂 |

### 汇总断言失败

```java
@Rule
public ErrorCollector collector = new ErrorCollector();

@Test
public void assertions(){
    collector.checkThat( value: 1, equalTo( operand: 2));
    collector.checkThat( value: 2, equalTo( operand: 2));
    collector.checkThat( value: 3, equalTo( operand: 2));
}
```

## jenkins

allure历史报告对比

allure generate allure

# Allure 官网介绍

Allure Framework is a flexible lightweight multi-language test report 

## 2. Get Started

### 2.2 Test execution

Before building a report you need to run your tests to obtain some basic test report data. Typically it might be a junit-style xml report generated by nearly every popular test framework. For example, suppose you have test reports automatically created by surefire maven plugin stored in the `target/surefire-reports`

### 2.3 Report generation

This is already enough to see the Allure report in one command:

`allure serve /home/path/to/project/target/surefire-reports/`

Which generates a report in temporary folder from the data found in the provided path and then creates a local Jetty server instance, serves generated report and opens it in the default browser. It is possible to use a `--profile` option to enable some pre-configured allure setting. junit profile is enabled by default, you will learn more about profiles in the following section.

This would produce a report with a minimum of information extracted from the xml data that will lack nearly all of the advanced allure features but will allow you to get a nice visual representation of executed tests.

## 3. Report structure

Once you’ve got the idea what the report does look like. You will probably want to get more data-rich reports. You might have to consider using one of the Allure adaptors for your testing framework, which will allow to collect much more information. Jump to the integrations section to learn more about integration with testing frameworks.

Typical report consists of ‘Overview’ tab, navigation bar, serveral tabs for different kinds of test data representation and test case pages for each individual test. ==Each Allure report is backed by a tree-like data structure, that represents a test execution process.== Different tabs allow to switch between the views of the original data structure thus giving a different perspective. Note that all tree-like representations including Behaviors, Categories, xUnit and Packages support filtering and are sortable.

### 3.1. Overview page

Entry point for every report would be the ‘Overview’ page with dashboards and widgets:

Overview page hosts several default widgets representing basic characteristics of your project and test environment.

* Statistics - overall report statistics.
* Launches - if this report represents several test launches, statistics per launch will be shown here.
* Behaviors - information on results aggregated according to stories and features
* Executors - information on test executors that were used to run the tests.
* History Trend - if tests accumulated some historical data, it’s trend will be calculated and shown on the graph.
* Environment - information on test environment

Home page widgets are draggable and configurable. Also, Allure supports it’s own plugin system, so quite different widget layouts are possible.

Navigation bar is collapsible and enables you to switch into several of the basic results overview modes.

### 3.2 Categories

Categories tab gives you the way to create custom defacts classification to apply for test results.

### 3.3 Suites

On the Suites tab a standard structural representation of executed tests, grouped by suites and classes can be found.

### 3.4 Graphs

Graphs allow you to see different statistics collected from the test data: statuses breakdown or severity and duration diagrams.

### 3.5 Timeline

Timeline tab visualizes retrospective of tests execution, allure adaptors collect precise timings of tests, and here on this tab they are arranged accordingly to their sequential or parallel timing structure.

### 3.6 Behaviors

For Behavior-driven approach, this tab groups test results according to Epic, Feature and Story tags.

### 3.7 Packages

Packages tab represents a tree-like layout of test results, grouped by different packages.

### 3.8 Test case page

From some of the results overview pages described above you can go to the test page after clicking on the individual tests. ==This page will typically contain a lof of individual data related to the test case: steps executed during the test, timings, attachments, test categorization labels, descriptions and links.==

## 4. Features

This section describes the main features of Allure. For example, you can group your tests by stories or features, attach files, and distribute assertions over a set of custom steps, among other features. All features are supported by Java test frameworks, so we only provide Java examples here. For details on how a particular adapter works with the test framework of your choice, refer to the adapter guide.

### 4.1 Flaky tests

In real life not all of your tests are stable and always green or always red. A test might start to “blink” i.e. it fails from time-to-time without any obvious reason. you could disable such a test, that is a trivial solution. However what if you do not want to do that? Say you would like to get more details on possible reasons or the test is so critical that even being flaky it provides helpful information? You have an option now to mark such tests in a special way, so the resulting report will clearly show them as unstable:

```java
@Flaky
public void aTestWhichFailsFromTimeToTime {
    ...
}
```

Here is what you get in the report if such a test failed.

> you can mark a whole test class as flaky as well.

### 4.2 Environment

To add information to Environment widget just create `environment.properties`(or `environment.xml`) file to `allure-results` directory before report generation.

*environment.properties*

```properties
Browser=Chrome
Browser.Version=63.0
Stand=Production
```

*environment.xml*

```xml
<environment>
	<parameter>
    	<key>Browser</key>
        <value>Chrome</value>
    </parameter>
    <parameter>
    	<key>Browser.Version</key>
        <value>63.0</value>
    </parameter>
    <parameter>
    	<key>Stand</key>
        <value>Production</value>
    </parameter>
</environment>
```

### 4.3 Categories

There are two categories of defects by default:

* ==Product defects (failed tests)==
* ==Test defects(broken tests)==

To create custom defects classification add `categories.json` file to `allure-results` directory before report generation.

*categories.json*

```json
[
  {
    "name": "Ignored tests", 
    "matchedStatuses": ["skipped"]
  },
  {
    "name": "Infrastructure problems",
    "matchedStatuses": ["broken", "failed"],
    "messageRegex": ".*bye-bye.*"
  },
  {
    "name": "Outdated tests",
    "matchedStatuses": ["broken"],
    "traceRegex": ".*FileNotFoundException.*"
  },
  {
    "name": "Product defects",
    "matchedStatuses": ["failed"]
  },
  {
    "name": "Test defects",
    "matchedStatuses": ["broken"]
  }  
]
```

:one: (mandatory) category name

:two: (optional) list of suitable test statuses. Default `["failed", "broken", "passed", "skipped", "unkonwn"]`

:three: (optional) regex pattern to check test error message. Default `".*"`

:four: (optional) regex pattern to check stack trace. Default `".*"`

Test result falls into the category if its status is in the list and both error message and stack trace match the pattern.



## 6.1 Pytest

### 6.1.1. Installation

### 6.1.2. Usage

### 6.1.3. Basic Reporting

### 6.1.4. Supported Pytest features

Some of the common Pytest features that the Allure report supports include xfails, fixtures and finalizers, marks, conditional skips and parametrization.

#### xfail

This is pytest way of marking expected failures:

```python
@pytest.mark.xfail(condition=lambda: True, reason='this test is expecting failure')
def test_xfail_expected_failure():
    
```

#### Conditional mark

#### Fixtures and Finalizers

Fixtures and finalizers are the utility functions that will be invoked by Pytest before your test starts and after your test ends respectively. Allure tracks invocations of every fixture and shows in full details wha methods with what arguments were invoked, preserving the correct sequence of the calls that were made.

You don’t need to mark your fixtures to make them visible in the report, they will be detected automatically for different scopes.

```python
@pytest.fixture(params=[True, False], ids=['param_true', 'param_false'])
def function_scope_fixture_with_finalizer(request):
    if request.param:
        print('True')
    else:
        print('False')
    def function_scope_finalizer():
        function_scope_step()
    request.addfinalizer(function_scope_finalizer)

    
@pytest.fixture(scope='class')
def class_scope_fixture_with_finalizer(request):
    def class_finalizer_fixture():
        class_scope_step()
  	request.addfinalizer(class_finalizer_fixture)
    

@pytest.fixture(scope='module')
def module_scope_fixture_with_finalizer(request):
    def module_finalizer_fixture():
        module_scope_step()
    request.addfinalizer(module_finalizer_fixture)
    
    
@pytest.fixture(scope='session')
def session_scope_fixture_with_finalizer(request):
    def session_finalizer_fixture():
        session_scope_step()
    request.addfinalizer(session_finalizer_fixture)
    
    
class TestClass:
    
    def test_with_scoped_finalizers(self,
                                    function_scope_fixture_with_finalizer,
                                   	class_scope_fixture_with_finalizer,
                                    module_scope_fixture_with_finalizer,
                                    session_scope_fixture_with_finalizer):
        stpe_inside_test_body()
```

Depending on an outcome of a fixture execution, test that is dependent on it may receive a different status. Exception in the fixture would make all dependent tests broken, `pytest.skip()` call would make all dependent test skipped.

```python
import pytest

@pytest.fixture
def skip_fixture():
    pytest.skip()
    
@pytest.fixture
def fail_fixture():
    assert False
    
@pytest.fixture
def broken_fixture():
    raise Exception("Sorry, it's broken")
    
def test_with_pytest_skip_in_the_fixture(skip_fixture):
    pass

def test_with_failure_in_the_fixture(fail_fixture):
    pass

def test_with_broken_fixture(broken_fixture):
    pass
```

#### Parametrization

You can generate many test cases from the sets of input parameters using `@pytest.mark.parametrize`.

All argument names and values will be captured in the report, optionally argument names will be replaced with provided string descriptions in the `ids` kwarg.

### 6.1.5. Allure Features

Allure currently supports almost every available feature except for environment with Pytest.

#### Steps

The first and probably most important aspect of the Allure report is that it allows to get a very detailed step-by-step representation of every test invocation. This is made possible with `@allure.step` decorator that adds invocation of the annotated method or function with provided arguments to the report.

Methods annotated 

#### Attachments

#### Descriptions

#### Titles

#### Links

### 6.1.6. Retries

### 6.1.7. Tags

#### BDD markers

#### Severity markers

